{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card Fraud Detection",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxj3s/wDkEAXbbQZCTqDxq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AditisGit/FraudCreditCardTransactionDetector/blob/main/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8UXe6V0donk"
      },
      "source": [
        "# CREDITCARD FRAUD DETECTION USING LINEAR REGRESSION\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cINqle3UfW_k"
      },
      "source": [
        "# Importing dataset from Kaggle:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKokMH7KR5ok"
      },
      "source": [
        "!pip install kaggle\r\n",
        "from google.colab import files \r\n",
        "loader = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndrLhzfPcp7g"
      },
      "source": [
        "!mkdir -p ~/.kaggle \r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a9adO9VcRZg"
      },
      "source": [
        "!kaggle datasets download -d mlg-ulb/creditcardfraud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRl1Y2mFdmtB"
      },
      "source": [
        "!pip install zip_files "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpuqUkO0d6ZF"
      },
      "source": [
        "from zipfile import ZipFile\r\n",
        "creditcard_data = 'creditcardfraud.zip'\r\n",
        "with ZipFile(creditcard_data,'r') as zip:\r\n",
        "  zip.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQKeBKsmfdRT"
      },
      "source": [
        "#Importing the required Python Libraries:\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZJAaZAFffe2"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np \r\n",
        "import seaborn as sns \r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import tensorflow as tf \r\n",
        "from keras.layers import Dropout, Dense, Flatten\r\n",
        "from keras.models import Sequential\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epie673Yg0HH"
      },
      "source": [
        "# Reading and making inferences from the dataset: \r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK5DRfZughK5"
      },
      "source": [
        "credit_df = pd.read_csv('creditcard.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aeBwYi3f6N2"
      },
      "source": [
        "credit_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz3dj-r0HQla"
      },
      "source": [
        "credit_df.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6BPjIEngNEM"
      },
      "source": [
        "credit_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaNXF8NjgRKn"
      },
      "source": [
        "credit_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmkFmQaufK6o"
      },
      "source": [
        "credit_df.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ_jKh2L9kMj"
      },
      "source": [
        "# Visualisation of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRSFZ66p5iHl"
      },
      "source": [
        "sns.catplot(data=credit_df, kind=\"bar\",x=\"Class\", y=\"Amount\", palette=\"dark\", alpha=.6, height=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDg_M9no9rgz"
      },
      "source": [
        "sns.scatterplot(data=credit_df, x='Class', y='Amount', palette='dark')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmATBeQchyGf"
      },
      "source": [
        "X = credit_df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']]\r\n",
        "y = credit_df[['Class']]\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w_yINLMfT45"
      },
      "source": [
        "scaler = StandardScaler()\r\n",
        "credit_df['Normalized Amount'] = scaler.fit_transform(credit_df['Amount'].values.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1vqCLq2gyx-"
      },
      "source": [
        "credit_df = credit_df.drop(['Normalized Amount'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnqI33VJg-4i"
      },
      "source": [
        "# Training the Model:\r\n",
        "\r\n",
        "---\r\n",
        "The model used for this project contains one input layer,one output layer and two hidden layers. The ReLU activation function is used for the first and hidden layers and the Output layer uses a Sigmoid activation function.\r\n",
        "The model is trained over five epochs and uses the adam optimizer and binary crossentropy function for loss to calculate gradient descent while compiling the model.\r\n",
        "The model is trained by splitting the dataset into Train and Test sets. The Training set contains 1,99,364 transactions and the test set contains 85,443 transactions. However, the dataset is highly unbalanced and contains only 492 fraudulent transactions.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5gGKTENY5q6"
      },
      "source": [
        "model = Sequential([\r\n",
        "                    Dense(units=20, input_dim=28, activation='relu'),\r\n",
        "                    Dense(units=15, activation='relu'),\r\n",
        "                    Dropout(0.2),\r\n",
        "                    Dense(units=10, activation='relu'),\r\n",
        "                    Dense(units=1, activation='sigmoid')\r\n",
        "\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gljftt6raxSc"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvh3D1r-bNqF"
      },
      "source": [
        "r = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFSDfHoZuWdI"
      },
      "source": [
        "# Visualising the Loss and Accuracy of predictions\r\n",
        "\r\n",
        "---\r\n",
        "A plot of the loss versus validation loss and accuracy versus calidation accuracy allows us to check if the model is being over-fitted or underfitted.\r\n",
        "The model trained here shows low loss and high accuracy and seems to be doing fine.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy1g0MtJoIO7"
      },
      "source": [
        "plt.plot(r.history['loss'],label='Loss')\r\n",
        "plt.plot(r.history['val_loss'],label='Val_loss')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF-XHdcPpIxz"
      },
      "source": [
        "plt.plot(r.history['accuracy'],label='accuracy')\r\n",
        "plt.plot(r.history['val_accuracy'],label='Val_accuracy')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqtJeJ1hpXS-"
      },
      "source": [
        "print(model.evaluate(X_test, y_test))\r\n",
        "p_test = model.predict(X_test).argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waQ9JKLNKIWs"
      },
      "source": [
        "The model shows a prediction accuracy of 0.9994"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g_eIz9LvDHr"
      },
      "source": [
        "# Evaluation of the model using a confuison matrix\r\n",
        "\r\n",
        "---\r\n",
        "A plot of the confusion matrix is a visualisation of the predictive analysis and enables us to understand its performance better.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9JUgJg1sS50"
      },
      "source": [
        "print(classification_report(y_test, p_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}